---
title: "Read ACLED summary data"
author: "Spencer Graves"
date: "2025-01-11"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::knitr}
  %\VignetteIndexEntry{Read ACLED summary data}
  %\usepackage[UTF-8]{inputenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

[Armed Conflict Location and Event Data (`ACLED`)](https://en.wikipedia.org/wiki/Armed_Conflict_Location_and_Event_Data) is a non-profit organization specializing in collecting incident-level data on conflicts that support analysis and crisis mapping in near real time. ACLED codes the dates, actors, locations, fatalities, and types of all incidents of political violence and demonstration events around the world as reports appear in the literature they monitor. The project began in 2005 focusing on African states. Its coverage expanded multiple times until 2021-01 when it covered the entirety of humanity, by which time it had over 1.3 million events in its database. [A pdf file gives the start data of coverage for different countries.](https://acleddata.com/acleddatanew/wp-content/uploads/dlm_uploads/2019/01/ACLED_Country-and-Time-Period-coverage_updatedFeb2022.pdf) These range from 1997-01 for continental Africa to 2021-01 for most of North America and Oceana (including Australia and New Zealand) and Antarctica. 

The [ACLED Explorer](https://acleddata.com/explorer/) makes it moderately easy for someone to download counts of either events or fatalities in a specific date range by "political violence", "organized violence", "demonstrations", "civilian targeting" or "all event types". Data can be grouped by "region", "country", `Admin1` and "Location". Counts can optionally be restricted to only specific actors or "actor types". Events can optionally be grouped by event type and by day or week. 

Long term, we'd like to build models of the evolution of the numbers of events and deaths by event type, month and country. Such models have two uses: 

- First to [compute the probability of detecting a reduction in the lethality of a particular conflict in a specific period of time if an intervention had an effect of a given magnitude (statistical power)](https://en.wikipedia.org/wiki/Power_(statistics)). 
- Then if a proposed intervention is actually implemented, the same models can be used to evaluate the efficacy of the intervention(s).

Before we do that, we first attempt simpler tasks: 

1. Read and summarize `ACLED` data in various ways. *[this vignette]*
2. Read World Bank (`WB`) data on population and level of econmic activity as Gross Domestic Product per capita (`GDPpc`) at both Purchasing Power Parity (`PPP`) and nominal: We need `PPP` to evaluate the impact of `GDPpc` and changes in `GDPpc` on the level of conflict. And we need nominal `GDP` to estimate budgets for certain types of interventions. (`GDP` is, of course, population times `GDPpc`.) 
3. Merge `ACLED` and `WB` data. 
4. Build static models of the relationships between `ACLED` and `WB` variables. 
5. Build time series models of the numbers of events and deaths by month and their relationships with other veriables like `GDPpc` and public health. We might expect that increases in events and deaths might both impact economic activity and public health and be influenced by previous changes in such other variables. 

## Extract, download and read `ACLED` data 

To make everything comparable, we downloaded events and fatalities from ACLED Explorer by country and event type for each month starting with 2021-01 as `*.csv` files. This involved two requests from "ACLED Explorer" for "Event Counts" separate from "Fatality Counts". For each extraction, we requested, (2) "All event types", (3) a custom date range starting with the first day of the first month requested and ending with the last day of the last month requested. We also requested (4) "Select All" regions and (5) countries. (6) We did NOT request "specific Admin1 units". (7) We asked to group the data by country. (8) We did NOT select specific actors or types of actors. But we DID want to see events groups by (9) event type and (10) time period: month. 

[Wickham and Bryan, *R Packages* (2ed, sec. 7.3 Raw data file)](https://r-pkgs.org/data.html#sec-data-extdata) recommend putting raw data files for a vignette in an `~inst/extdata` subdirectory of the package. 

There's a problem with this however, because the `ACLED` data extracts, which I renamed `acled_aggregated_2021events.csv` and `acled_aggregated_2021fat.csv`, containing events and fatalities data, respectively, were 2.5 MB each. For CRAN, ["As a general rule, neither data nor documentation should exceed 5MB"](https://www.thecoatlessprofessor.com/programming/r/size-and-limitations-of-packages-on-cran/). 

I met these limits by doing two things: 

1. Putting these large files in an `extdata` subdirectory of the *parent* of the `acledrsg` package directory *and* by putting much smaller extracts in `~/acledr/inst/extdata`. These smaller files contained sample data from 2023-12-01 to 2024-01-31.  
2. Writing a function `findSubdir` to look first for an `extdata` file in the parent of the package directory, then in the package directory itself, and then in an `inst` subdirectory of the package. (Wickham and Bryan suggested functions that were supposed to be able to do this, but I could not make them work. The function I wrote worked for this purpose at least locally and in GitHub Actions.)

On 2024-12-07 GitHub Action was throwing an error on this vignette. To isolate that error, I added a variable `run` with the following acceptable values: 
1. `noSearch` to stop before searching for `extdata`, which should contain data files to be read. 
2. `noDir` to stop before looking for `*.csv` files in `extdata`. 
3. `noRead` to stop before attempting to read `*events.csv` and `*fat.csv` (fatalities) files that were found.
4. `read` to stop just after reading the files that were found. 
5. `allButSave` to run the entire vignette except for the final step of saving the datasets created. 
6. `all` to run the entire vignette. 

With `run` = `noSearch` or `noRead`, the package checked fine both on my local computer and on GitHub. With `run` = any of the other three, the package checked fine locally but failed with GitHub Action on all 5 platforms. 

GitHub Action worked through obtaining `extdata` path to the subdirectory of the `acledrsg` package with `run = "findExtr"` but failed when actually trying to read such files with `run = "readExtr"` or `"all"`. 
```{r extdata}
run <- c("noSearch", "noDir", "noRead", 'read', "allButSave", "all")[5]
if(run %in% c("noDir", "noRead", 'read', "allButSave", "all")){
  library(acledrsg)
  (extdata <- findSubdir())
}
```

Now find the deaths and events files. 

```{r d_e_files}
if(run %in% c("noRead", 'read', "allButSave", "all")){
  (csvFiles. <- dir(extdata, pattern='\\.csv$'))
  (csvFiles <- dir(extdata, pattern='\\.csv$', 
                   full.names = TRUE))

  if((length(csvFiles)<1) || (max(nchar(csvFiles)<1))){
    stop('No csv files found in extdata = ',
         extdata)
  }
  (eventFile <- dir(extdata, pattern='events\\.csv$', 
                    full.names = TRUE))
  if((length(eventFile)<1) || (max(nchar(eventFile)<1))){
    stop('No eventFile found in csvFiles = ',
         paste(csvFiles, collapse=', '))
  }

  (deathFile <- dir(extdata, pattern='fat\\.csv$', 
                  full.names = TRUE))
  if((length(deathFile)<1) || (max(nchar(deathFile)<1))){
    stop('No deathFile found in csvFiles = ',
         paste(csvFiles, collapse=', '))
  }
}
```

Let's read these two files and confirm that they are identical except for the last column. 

**NOTE: This vignettes knits with no apparent errors to this point, but the following `readDat` snippet throws an error in GitHub Action on all platforms: With `run %in% c('noRead', 'all')`, it fails. With `run = 'noSearch'`, GitHub Action works, as of 2024-12-08. 

```{r readDat}
if(run %in% c('read', "allButSave", "all")){
  ndF <- length(deathFile)
  if(ndF>1){
    cat('more than one deathFile:\n', 
        paste(deathFile, collapse='\n'), 
        '\nusing the last one.')
  }
  deaths <- read.csv(deathFile[ndF])
  
  neF <- length(eventFile)
  if(neF>1){
    cat('more than one eventFile:\n', 
        paste(eventFile, collapse='\n'), 
        '\nusing the last one.')
  }
  events <- read.csv(eventFile[neF])
}
```

```{r chkDat}
if(run %in% c("allButSave", "all")){
  all.equal(deaths[-4], events[-4])
}
```

Looks good. Let's combine them to create `ctryMoEv`. We then summarize those: 

- over `Event.month` to create `ctryEv` 
- and across `Event.Type` to create `ctryMo`. 

Then summarize `ctryEv` further 

- across `Country` to get `Ev` 
- and across `Event.Type` to get `ctry`. 

```{r ctryMoEv}
if(run %in% c("allButSave", "all")){
  ctryMoEv <- events
  ctryMoEv$Event.month <- as.Date(events$Event.month)
  (firstMo <- min(ctryMoEv$Event.month))
  (lastMo <- max(ctryMoEv$Event.month))

  ctryMoEv$Deaths <- deaths$Fatalities
  ctryMoEv$deathsPerEvent <- (deaths$Fatalities/events$Events)
  str(ctryMoEv)
  range(ctryMoEv$Event.month)
}
```

Before summarizing, let's compute `nCtries`, `nMonths`, and `nTypes`: 

```{r factorNobs}
if(run %in% c("allButSave", "all")){
  Ctries <- table(ctryMoEv$Country)
  (nCtries <- length(Ctries))

  Months <- table(ctryMoEv$Event.month)
  (nMonths <- length(Months))

  Types <- table(ctryMoEv$Event.Type)
  (nTypes <- length(Types))

  (Nobs <- nrow(ctryMoEv))
  all.equal(Nobs, nCtries*nMonths*nTypes )
}
```

### `ctryMo` <- sum (`Events`, `Deaths`) by (`Country`, `Event.month`) across `Event.Type`

```{r ctryMo}
if(run %in% c("allButSave", "all")){
  library(dplyr)
  ctryMo <- (ctryMoEv %>% group_by(Country, Event.month) 
           %>% summarize(Events=sum(Events), Deaths=sum(Deaths)))
  ctryMo$DeathsPerEvent <- with(ctryMo, Deaths/Events)
  dim(ctryMo)
  head(ctryMo, 2)
  tail(ctryMo, 2)
}
```

### `ctryEv` <- Sum (`Events`, `Deaths`) by (`Country`, `Event.Type`) across `Event.month`

```{r ctryEv}
if(run %in% c("allButSave", "all")){
  str(Nmo <- table(ctryMoEv$Event.month))
  table(Nmo)

  ctryEv <- (ctryMoEv %>% group_by(Country, Event.Type) 
           %>% summarize(Events=sum(Events), Deaths=sum(Deaths)))
  ctryEv$DeathsPerEvent <- with(ctryEv, Deaths/Events)
  dim(ctryEv)
  head(ctryEv, 2)
  tail(ctryEv, 2)
}
```

### `ctry` <- sum (`Events`, `Deaths`) by `Country` 

```{r ctry}
if(run %in% c("allButSave", "all")){
  ctry <- (ctryEv %>% group_by(Country) 
           %>% summarize(Events=sum(Events), Deaths=sum(Deaths)))
  ctry$DeathsPerEvent <- with(ctry, Deaths/Events)
  ctry <- as.data.frame(ctry)
  rownames(ctry) <- ctry$Country
  dim(ctry)
  head(ctry, 2)
  tail(ctry, 2)
}
```

### `MoEv` <- Sum (`Events`, `Deaths`) by (`Event.month`, `Event.Type`) across `Country`

```{r MoEv}
if(run %in% c("allButSave", "all")){
  str(Nctry <- table(ctryMoEv$Country))
  table(Nctry)

  MoEv <- (ctryMoEv %>% group_by(Event.month, Event.Type) 
           %>% summarize(Events=sum(Events), Deaths=sum(Deaths)))
  MoEv$DeathsPerEvent <- with(MoEv, Deaths/Events)
  dim(MoEv)
  head(MoEv, 2)
  tail(MoEv, 2)
}
```

### `Mo` <- sum (`Events`, `Deaths`) by `Event.month` 

```{r Mo}
if(run %in% c("allButSave", "all")){
  Mo <- (ctryMoEv %>% group_by(Event.month) 
           %>% summarize(Events=sum(Events), Deaths=sum(Deaths)))
  Mo$DeathsPerEvent <- with(Mo, Deaths/Events)
  dim(Mo)
  Mo
}
```

### `Ev` <- sum (`Events`, `Deaths`) by `Event.Type` 

```{r Ev}
if(run %in% c("allButSave", "all")){
  Ev <- (ctryEv %>% group_by(Event.Type) 
           %>% summarize(Events=sum(Events), Deaths=sum(Deaths)))
  Ev$DeathsPerEvent <- with(Ev, Deaths/Events)
  dim(Ev)
  Ev
}
```

Looks sensible. 

## Save 

Save `ACLEDpopGDP`.

```{r}
#| label: save
if(run =="all"){
  usethis::use_data(ctryMoEv)
  usethis::use_data(ctryMo)
  usethis::use_data(ctryEv)
  usethis::use_data(ctry)
  usethis::use_data(MoEv)
  usethis::use_data(Mo)
  usethis::use_data(Ev)
}
```

